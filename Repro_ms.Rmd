---
title: "| Ciencia reproducible: qué, por qué, cómo \n| Reproducible science: what,
  why, how\n"
  
author: Francisco Rodríguez-Sánchez^1^, Antonio Jesús Pérez-Luque^2^, Sara Varela^3^,
  Ignasi Bartomeus^1^ (*order to be determined*)
  
output:
  word_document:
    fig_caption: yes
    highlight: null
    reference_docx: Ecosistemas_template.docx

bibliography: references.bib
csl: american-journal-of-botany.csl
---

> (1) Departamento de Ecología Integrativa, Estación Biológica de Doñana (EBD-CSIC), Consejo Superior de Investigaciones Científicas, Avda. Américo Vespucio s/n, E-41092 Sevilla, España.

> (2) Laboratorio de Ecología (iEcolab), Instituto Interuniversitario Sistema Tierra (CEAMA), Universidad de Granada, Avda. del Mediterráneo s/n, Granada 18006, España.

> (3) Departamento de Ciencias de la Vida, Facultad de Biología, Ciencias Ambientales y Química, Universidad de Alcalá, Campus Universitario. Ctra. Madrid-Barcelona, Km. 33,600, 28805 Alcalá de Henares, Madrid, España.


> Autor para correspondencia: F. Rodríguez-Sánchez [frodriguez.work@gmail.com]



```{r knitr_setup, include=FALSE, cache=FALSE}
 
library(rmarkdown)
library(knitr)

### Chunk options ###

# Modify at your will #

## Text results
opts_chunk$set(echo = TRUE, warning=TRUE, message=TRUE)

## Code decoration
opts_chunk$set(tidy=TRUE, comment = NA, highlight = TRUE)

## Cache
opts_chunk$set(cache = 2, cache.path = "output/cache/")
opts_chunk$set(cache.extra = rand_seed)

## Plots
opts_chunk$set(fig.path = "output/figures/")
opts_chunk$set(dpi = 300, fig.align = "default")   # may want 'center' sometimes

# Figure format
opts_chunk$set(dev='png')  # e.g. choose among 'pdf', 'png', 'svg'...
# may include specific dev.args as a list... see knitr help


```


```{r citations_setup, include=FALSE, cache=FALSE}

library(knitcitations)
cleanbib()   
cite_options(citation_format = "pandoc")

if (file.exists("refs2import.bib")) 
  refs_from_file <- read.bibtex("refs2import.bib", check=FALSE)

```


# Resumen

> Bla, bla, bla

# Abstract

> Blah, blah, blah

# Palabras clave

> reproducibilidad; ciencia abierta; etc (4-6 keywords)


# Keywords

> reproducibility; open science; etc (4-6 keywords)


# Introducción 

Un científico pasa semanas o meses intentando implementar un nuevo método de análisis publicado recientemente, a partir de la escueta descripción proporcionada en el artículo. Otro, extrañado por los resultados de un trabajo reciente, solicita a los autores los datos para reanalizarlos, pero los autores se niegan a compartir sus datos o los han perdido. Un jefe de grupo intenta repetir un análisis que publicó hace unos años, ahora con un nuevo dataset, pero el postdoc que se encargó de eso ya no está en el grupo y nadie más sabe o recuerda cómo hacerlo. En otro caso, un investigador es invitado a participar en un meta-análisis pero los datos necesarios se perdieron con el último ordenador, o se encuentran en un formato ilegible hoy día. Finalmente, un doctorando detecta, poco antes de enviar su manuscrito, un error en los datos, y tiene que emplear varios días (o semanas) para rehacer todos los análisis y actualizar todas las tablas y figuras del manuscrito, antes de poder enviarlo. [propongo poner el parrafo en primera persona: E.g. A menudo pasamos semanas... Cuando solicitamos datos no es raro que ... Inclusso nuestros propios datos son perdidos, o cuando detectamos fallos... solo una idea.]

Todas estas escenas son desgraciadamente frecuentes en el día a día de los científicos, y son evidencia del grave problema de reproducibilidad en Ciencia. La inmensa mayoría de los artículos científicos no son reproducibles, esto es, es muy difícil o incluso imposible trazar claramente el proceso de obtención de los resultados y volver a obtenerlos (reproducirlos), !incluso tratándose del mismo equipo de autores! ?Cuántas veces hemos querido revisitar un análisis hecho unos meses o años antes y no hemos sido capaces, bien porque los datos no están disponibles o no recordamos cómo hacerlo? Cuánto tiempo perdemos inútilmente en intentar reproducir algo (un análisis estadístico, una figura, una tabla) ya hecho previamente? [Bourne: 280 h] ?O en regenerar una figura tras corregir un error en los datos?

# Qué es la ciencia reproducible?

La reproducibilidad es uno de los principios esenciales del método científico, y se refiere a la capacidad que tenga una prueba o experimento de ser replicado. De hecho, el formato actual de todos los articulos cientificos dedica un apartado entero a explicar detalladamente el proceso seguido para obtener los resultados con el objetivo de que otros puedan validarlos. Historicamente, el enfasis ha estado en dar suficiente información para que el resultado pueda repetirse en otro laboratorio, es decir, volver a recoger datos, analizarlos y asegurarse que los resultados son consistentes [http://bioscience.oxfordjournals.org/content/56/12/958.full]. Sinembargo, se ha descuidado más que la obtencion del resultado presentado pueda ser trazado y reproducido exactamente como se presenta en el articulo. Los dos conceptos, reproducibilidad, y repetibilidad (o replicabilidad) en el tiempo estan altamente interconnectados, pero aqui queremos hablar sobretodo del primero, ya que si presentamos los resultados de forma reproducible, seguro que seran faciles de repetir (con exito o no) en el futuro. Sin embargo, los tres o cuatro parrafors de material y metodos, dificilmente continen toda la informacion necesaria. 

En ecologia especialmente, el proceso de toma de datos en campo o laboratorio es dificil de reproducir por que intervienen componentes estocasticos (e.g. comportamiento animal). Sí se puede replicar, pero no reproducir, pero el resto del proceso, sobretodo el manejo y analisis de datos puede ser completamente reproducible. De hecho cada vez hay más papers... Parrafo ejemplos:
Ejemplos de papers 100% reproducibles: Fitzroy en Journal of ecology? 
Ejemplos datos publicos re-analizados: PNAS paper en huracanes.

# Por qué es necesaria la reproducibilidad en Ciencia?

El concepto de reproducibilidad esta ligado al de transparencia y movimiento de ciencia abierta. Con el incremento de la complejidad por ejemplo de metodos estadisticos, tambien incrementa la posibilidad de cometer errores. Como cientificos, no podemos garantizar que ningún resultado/paper es correcto, pero sí reproducible [Peng]. Sin ebargo, abogamos por que la reproducibilidad ha de nacer de la uno mismo, y ha de ser una forma de dar confianza en nuestros resultados, y no ha de ser impuesta por la desconfianza. Hemos de apelar a los cientificos a querer apostar por la transparencia para así mejorar la calidad de la ciencia. No hemos de tener la obligación de hacerlo, sino el deso de hacer nuestro proceso de trabajo reproducible.

Hacer ciencia reproducible no solo es bueno para la Ciencia en mayusculas, sino tambien para ti (para nosotros) como cientificos. Enseñar la reproducibilidad de tus resutados te posiciona desde un punto de vista estrategico como cientifico comprometido. Das un sello de calidad a tu ciencia, especialmente ahora cuando aun no es la norma. Por ejemplo, Molecular Ecology states that "Papers with exemplary data and code archiving are more valuable for future research, and, all else being equal, will be given higher priority for publication" (http://onlinelibrary.wiley.com/journal/10.1111/%28ISSN%291365-294X/homepage/ForAuthors.html). Adoptarla ahora una estrategia reproducible te pone por delante, sinembargo, cuando sea un estandard de aqui a pocos años (e.g. Methods & ecology and Evolution ya esta trabajando para hacer obligatorio depositar el codigo usado para el paper), ya no tendra merito.

Además de estas razones, en las siguientes secciones destacamos como el hacer ciencia reproducible puede mejorar tu rendimiento y eficiencia.

# Cómo hacer Ciencia reproducible

La ciencia reproducible es dura.

Parrafo sobre barreras para adoptar un flujo reproducible. Tornar las barreras en puntos positivos. Te fuerza a ser más limpio, ordenado, y seguro de tus resultados. Es duro, pero es bueno. 

Parrafo sobre estrategias para hacer el paso. No es cuestion de todo o nada. De hecho, intentar ser 100% reproducible de golpe lleva a frustración y abandono. Se trata de ganar batallas y empezar por las faciles. Quizas ejemplos de los propios autores.

K Broman guides are very good. Also paper Tao of open science (Ecosphere)

Esta sección está subdividida en subsecciones.


## Toma y Manejo de datos [NACHO]

Aunque en este articulo nos centramos en como las nuevas tecnologias nos permiten hacer nuestro flujo de trabajo reproducible desde que tenemos los datos hasta que publicaos el paper, no hay que olvidar que el proceso empieza mucho antes de tener una base de datos. Empieza con el diseño del proyecto y la toma de datos.

El propio escrito inicial del proyecto, aparte de para pedir financiación, sirve para poner por escrito hipotesis a testar y una hoja de ruta que describe por que, que y como queremos realizar el proyecto. Escribir protocolos detallados antes de coger los datos, y actualizarlos con las eventualidades que en ecologia siempre surgen, es el primer paso para poder replicar el proceso que se ha seguido. Esto lleva tiempo, y es tentador explicar verbalmente que datos vamos a tomar al equipo de trabajo, pero es la unica forma de dejar un registro, y no olvidar ningún detalle en la sección de "Material y metodos". Sobra decir, que preparar tablillas pre-definidas para entrar datos en campo tambien asegura que no nos dejaremos ningun dato relevante.

Automatizar la toma de datos para que sea reproducible es algo más complicado y variara enormemente segun el tipo de datos con los que trabajemos. De todas maneras hay algunas practicas más o menos comunes que pueden servir de guia. El primero es que las muestras físicas, cuando las haya, y los datos digitales siempre han de estar conectados por un indicador único. Esto hara que qualquier dato pueda ser verificado (mayormente por nosotros mismos) en el futuro. Preservar estas muestras físicas en el tiempo es de vital importancia, pero tremendamente dificil, ya que normalmente no hay presupuesto para ello, y dependiendo se su naturaleza requieren de costosa preservación y/o ocupan gran volumen. Pensar en colecciones permanentes que puedan alojar estas muestras es a veces una buena opción. Por ejemplo, en el caso de especimenes debidamente identificados, estos pueden donarse a museos. 

Cuando los datos se toman directamente en campo, es importante que estos sean repetibles. Es decir, que se tomen de manera objetiva (e.g. numeros exactos) y no subjetiva (e.g. porcentages estimado) y que no haya un sesgo por observador (e.g. observadores con diferente experiencia). En el caso que se necesiten datos subjetivos, es importante cotejar quan repetibles es el resultado comparando medidas identicas repetidas por el mismo observado o entre observadores. Por ejemplo, en biologia del comportamiento, donde se suelen medir comportamientos, es comun  reportar esta repetibilididad en medir comportamientos, pero esto aplica tambien a datos más simples, donde tendemos a confiar en que no haya sesgo. Este tipo de resultados deben ir en el material suplementario (e.g. Winfree papers). Otra practica relacionada es medir los datos de menera "ciega" (sin saber que tratamiento es cuando tomas datos) siempre que sea posible, ya que el sesgo inconsciente que podemos introducir es muy grande (ref). La parte de toma de datos sigue confiandose a la breve reseña expuesta en el material y metodos, sin embargo, apoyar esta explicación con tests propios de repitibilidad en su obtención, y dar los detalles de forma rigurosa pueden significar un cambio importante. Por un lado, aportar estos datos contribuyen a dar confianza al lector en tus resultaod, por otro, incluir detalles de que protocolos no funcionaron, o se hubieron de adaptar, puede salvar muchas horas a alguin interesado en repetir esa clase de muestreo.

Entrar datos en un soporte digital es una de las partes más tediosas y aparantemente fáciles, pero propensa a generar errores. Usar bases de datos (o hojas de calculo) con estructuras ordenadas (Whickham 2014 Tidy data) y con campos de entrada pre-fijados (e.g. que solo las opciones previamente definidas sean aceptadas) ayuda a minimizar estos errores. Este tambien es el momento de crear los metadatos, ya que es cuando estan frescos en la memoria y el coste es bajo. Hay paquetes de R que facilitan este proceso usando estructuras de matadatos estandard como EML (ref al paquete de ropensci). Si no completas lo metadatos a la vez que los datos, lo más probable es que no lo hagas nunca, ya que cuando ha acabado el proyecto no recuerdas bien las cosas, y "da mucho trabajo". Sin embargo, tener bien documentado los datos no solo es bueno para compartir datos, sino como recalcamos en este articulo, para ti mismo en tres meses vista.

Una vez los datos estan en una base de datos, o simplemente un o varios csv's es el momento de limpiar los datos. Algo que hay que hacer de forma reproducible. 

## Análisis (R) y escritura (Rmarkdown) [PACO]

Yo pondria aquí manejo de datos (manipulacion de datos nunca sobre el original, dplyr, regex, etc...)

## Control de versiones (git & github) [ANTONIO]
El *control de versiones* es un sistema que registra los cambios que se realizan sobre un archivo (o conjunto de archivos) a lo largo de la historia del mismo, permitiendo restarurar una versión específica del archivo en cualquier momento. 

El control de versiones está instalado en la vida de los científicos y lo utilizamos en una o varias etapas durante el desarrollo cualquier investigación. Una forma sencilla de llevar a cabo un control de versiones, y quizá la mas común, consiste en realizar duplicados de los archivos (o de los directorios) con nombres poco informativos de los cambios aplicados (Figura *phd_comics*). Esta aproximación es muy simple pero también muy propensa a cometer errores (e.g. modificar, sobrescribir el archivo incorrecto). 

#### De los sistemas de control de versiones locales a los distribuidos. 
Para evitar este tipo de errores surgieron los *sistemas de control de versiones locales* donde los cambios sobre los archivos se mantenían bajo control en una base de datos. Sin embargo estos sistemas locales no permitían la colaboración, para lo cual se desarrollaron los *sistemas de control de versiones centralizados*, que consisten un servidor que contiene todos los archivos versionados y varios clientes que descargan los archivos desde ese lugar central. Este sistema, aunque ha sido ampliamente utilizado (Subversion, Perforce) presenta algunas desventajas: no es posible colaborar o guardar cambios si el servidor central está caido; pérdida de información en caso de que se corrompan los discos duros que almacenan la información en el servidor central, etc. Es por ello que surgieron los sistemas de control de versiones distribuidos (como Git o Mercurial) donde los clientes no solo descargan la última instantantea del archivo sino que replican el repositorio completamente, de tal forma que se hace una copia de seguridad de todos los datos. 

Añadiria algo más practico y menos arduo para animar a la gente a usarlo.


## Paquetes en R [SARA]

Una vez iniciado un proyecto para el cual estamos programando distintos análisis en forma de diferentes scripts en R, el método óptimo para organizar el código que vayamos generando es crear un paquete de R. La principal razón para hacer esto es que cualquier otra manera de organizar nuestro código (e.g. creando una carpeta con subcarpetas dentro de nuestra carpeta principal con los archivos relacionados con el manuscrito en ciernes) se hará ingobernable a medida que pase el tiempo y que nuestro código se complique. [NB: yo discrepo aqui, creo que si no tienes funciones propias, y la mayoria de gente que lea esto no tiene, con un proyecto de Rstudio vas sobrado]

Crear un paquete para reunir los scripts, la documentación de las funciones y los tests de las funciones, en contra de lo que pudiera parecer, no es un proceso difícil. Se trata de una estructura estándar en las cual las funciones van a funcionar (valga la redundancia), donde especificaremos las dependencias de nuestras funciones (qué otros paquetes estamos utilizando, y lo que también es muy importante, qué versiones de estos paquetes), además describiremos las funciones que hemos desarrollado y daremos ejemplos de uso para que un usuario externo (e incluso nosotros mismos en el futuro) pueda entender qué resultados va obtener y en qué formatos. 

De esta manera, un paquete de R es una estructura estándar que ayuda a entender nuestro código a usuarios externos (y a nosotros mismos), y que además es fácilmente compartible. De este modo estaremos facilitando el trabajo en equipo y el desarrollo de utilizades más complejas (que necesariamente requieren de un equipo de desarrolladores), usando además un programa de control de versiones (como GIT) y compartiendo el código en un repositorio público (como https://github.com).

Por todas estas razones, si queremos crear un proyecto de ciencia abierta y colaborativa en el cual programemos nuestras funciones en R, la manera óptima de hacerlo es creando un paquete de R a medida que vamos programando las funciones.

### Estructura estándar de un paquete de R

De manera general un paquete de R es una carpeta que debe tener al menos 3 subcarpetas (R, man y tests/testthat) y dos archivos de texto (DESCRIPTION y NAMESPACE) (e.g. https://github.com/ropensci/paleobioDB, leer Wickham 2015.R packages: organize, test, document and share your code, O'Reilly)

#### R

En esta carpeta será donde se guardan los archivos .R, osea, nuestros scripts de R. Cada función deberá llevar escrita su documentación inmediatamente encima de ella usando roxygen2 (https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html) (para ver un ejemplo de una función real y su documentación escrita usando roxygen2 ver https://github.com/ropensci/paleobioDB/blob/master/R/pbdb_taxonomic_functions.R). Además tendremos que crear un archivo .R que se llame myfirstpackage-package.R, y en el cual expliquemos qué hace y como funciona nuestro paquete y que estará escrito en roxygen2 (https://github.com/ropensci/paleobioDB/blob/master/R/paleobioDB-package.R).

#### man

En esta carpeta se guardarán los archivos .Rd, es decir, los archivos de ayuda que se abrirán cuando se use la función ? y que además forman el manual oficial del paquete en pdf. Estos archivos no se deben escribir a mano sino que se crean cuando se ejecuta el comando roxygenize, que lee la documentación que hemos generado previamente para cada función de R (https://github.com/ropensci/paleobioDB/tree/master/man)

#### Tests/testthat

Además, debemos incorporar tests para cada función para comprobar que las funciones realmente están haciendo lo que realmente queremos. Los test son scripts de R que comprueban cada función (son archivos .R, ver https://cran.r-project.org/web/packages/testthat/testthat.pdf). Estos tests son fundamentales a la hora de mantener un paquete porque cuando los paquetes crecen y se hacen complejos las interdependencias entre funciones son menos evidentes, así que podríamos llegar a modificar una función sin darnos cuenta de que al hacerlo estamos rompiendo otra que depende de ella (y las razones pueden no ser evidentes a primera vista, e.g., cuestiones de formato de los datos). Para ver un ejemplo real de tests abrir: https://github.com/ropensci/paleobioDB/tree/master/tests/testthat.

#### DESCRIPTION

Es un archivo de texto en el cual se especifica el nombre del paquete, su versión, los autores, emails, las dependencias que tiene, etc. (ver https://github.com/ropensci/paleobioDB/blob/master/DESCRIPTION) (Nota: editar DESCRIPTION con RStudio, nunca con el block de notas).

#### NAMESPACE

Es un archivo de texto que se genera automáticamente al ejecutar el comando roxygenize en el cual se especifican los nombres de las funciones que estarán disponibles al cargar nuestro paquete, que serán nuestras funciones propias y las funciones que importemos o de las que dependamos. Si nuestro paquete tiene una función con el mismo nombre que otro que se haya cargado antes R genera un mensaje informando del problema (colisión de nombres). Para evitar colisiones de nombres puedes aplicar un prefijo a las funciones de tu paquete de forma que sus nombres no coincidan con los de ninguna otra función que haya sido programada en R.

#### Crear el paquete

Finalmente, después de haber ejecutado el comando roxygenize para generar los manuales y el NAMESPACE, podemos crear nuestro paquete ejecutando las siguientes líneas desde el símbolo del sistema o del bash:

```coffee
cd..
R CMD build --resave-data myfirstpackage
```

Si nuestro paquete pasa el check –as-cran sin ningún warning podríamos incluso compartirlo en el CRAN de R. 

```coffee
R CMD check --as-cran myfirstpackage_0.1.tar.gz
```


## Dependencias externas [PACO]

Todo análisis reposa sobre plataformas o paquetes de software que suelen evolucionar con el tiempo. Así, cambios en paquetes de R, o el mismo R base, pueden hacer que nuestro análisis deje de ser reproducible en poco tiempo (semanas, meses), incluso habiendo seguido los protocolos de reproducibilidad esbozados más arriba. De manera que, para asegurar que nuestro proyecto siga siendo reproducible en el futuro, necesitamos (i) registrar las dependencias externas de nuestro análisis (e.g. paquetes de R), y (ii) asegurar de alguna forma el acceso a versiones pasadas de dicho software. Para el primer punto, es tan sencillo como ejecutar `sessionInfo()` al finalizar el análisis en `R`. Este comando devuelve una lista de todos los paquetes utilizados y su versión (Figura?). El segundo punto es algo más complejo, aunque existen distintas opciones que difieren significativamente en cuanto a versatilidad y facilidad de manejo. Entre los más sencillos se encuentran los paquetes `rctrack` (ref), `checkpoint` (ref) y `packrat` (ref). [TABLA COMPARATIVA] Mientras `rctrack` y `packrat` optan por almacenar una copia local de todos los paquetes utilizados en un proyecto, `checkpoint` simplemente rastrea los paquetes necesarios (esto es, llamadas a `library` o `require`) y descarga la versión correspondiente a la fecha que nosotros especifiquemos (link to tutorial). `checkpoint` sólo es compatible con paquetes incluidos en el repositorio CRAN, mientras que `packrat` es capaz de sincronizar también paquetes instalados desde GitHub u otro repositorio. Finalmente, `rctrack` es capaz de generar, de manera automática, un único fichero `RData` o `zip` conteniendo todos los datos y funciones necesarios para correr un análisis. Los tres paquetes son, por tanto, muy fáciles de utilizar y permiten tanto compartir código como asegurar su reproducibilidad de manera automática. Finalmente, desde hace muy poco tiempo existen también otras alternativas más versátiles y avanzadas, como `drat` (ref) o `rocker` (ref), más similares a una máquina virtual.

## hay que decir algo de data preservation in the long term??
quizas si, el paper de Nature con la figura de datos perdidos por año transcurrido es buenisima, la puedo recuperar.

Para acabar, queriamos poner la siguiente cita extraida de ...

"You can't reproduce… if you don't understand where a number came from.
You can't reproduce… what you don't remember. And trust me: you won't.
You can't reproduce… what you've lost. What if you need access to a file as it existed 1, 10, or 100, or 1000 days ago? - incremental back up (Git, Dropbox, Time machine...)"

Las herramientas expuestas anteriormente te ayudaran, sobretodo a ti mismo, pero tambien a los otros, a entender tus analysis, a recordar los que has hecho, a no perder datos, ni analysis y hacer mejor ciencia. 






# Referencias

Or cite by doi, e.g. `r citet("10.1098/rspb.2013.1372")`, thanks to `knitcitations` package `r citep(citation("knitcitations"))`. 


# Tablas

Se aportarán los encabezamientos tanto en castellano como en inglés, en letra Arial 10 y en página independiente.



# Pies de figura

Página independiente. En castellano e inglés. Letra Arial 10.



# Figuras 

En páginas independientes

- [Peng Science 2011](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3383002/bin/nihms382015f1.jpg)
- [Broken workflow](http://pakillo.github.io/Rmarkdown_talk_SevillaR_Nov2014/#/5)
- [Git & version control](http://pakillo.github.io/Rmarkdown_talk_SevillaR_Nov2014/#/19)



# Mover esta lista de referencias a la sección de 'Referencias', más arriba en documento final (Word).

```{r generate_references, cache=FALSE, include=FALSE, results='hide'}
write.bibtex(file="references.bib")
```









